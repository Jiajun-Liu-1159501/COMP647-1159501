{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e7ca99",
   "metadata": {},
   "source": [
    "## Device initialization\n",
    "\n",
    "This section initializes the computational environment for the project. It performs three critical tasks:\n",
    "\n",
    "1. Detects available hardware (CPU vs GPU)\n",
    "2. Configures PyTorch to use the optimal compute device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fc9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is mps available? True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import types\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import copy\n",
    "\n",
    "import gensim.downloader as api\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Check if MPS is available for acceleration\n",
    "print('Is mps available?', torch.mps.is_available())\n",
    "\n",
    "# Set the device to MPS if available, otherwise use CPU\n",
    "device = torch.device('mps' if torch.mps.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2e7ce",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "\n",
    "This section loads the SST dataset from local files and processes it for binary sentiment classification.\n",
    "\n",
    "4 files are loaded from the `SST2-Data/stanfordSentimentTreebank/` folder:\n",
    "\n",
    "### 1. `datasetSentences.txt`\n",
    "\n",
    "Contains all sentences extracted from movie reviews, this is the primary data source containing the text we want to classify.\n",
    "\n",
    "- Column 1: `sentence_index` - Unique identifier for each sentence\n",
    "- Column 2: `sentence` - The actual text of the sentence\n",
    "\n",
    "### 2. `datasetSplit.txt`\n",
    "\n",
    "Specifies which dataset split each sentence belongs to, ensures using the standard train/dev/test splits.\n",
    "\n",
    "- Column 1: `sentence_index` - Links to sentences in `datasetSentences.txt`\n",
    "- Column 2: `splitset_label` - Split assignment\n",
    "  - **1** = Training set\n",
    "  - **2** = Test set\n",
    "  - **3** = Development/Validation set\n",
    "\n",
    "### 3. `dictionary.txt`\n",
    "\n",
    "Maps all phrases (including sub-phrases) to unique IDs, acts as a lookup table to connect sentences to their sentiment labels, as a bridge between `datasetSentences.txt` and `sentiment_labels.txt`.\n",
    "\n",
    "- Column 1: `phrase` - Text of the phrase (can be a word, sub-phrase, or complete sentence)\n",
    "- Column 2: `phrase_id` - Unique integer identifier\n",
    "\n",
    "### 4. `sentiment_labels.txt`\n",
    "\n",
    "Contains sentiment scores for all phrases, provides the ground truth labels for training our sentiment classifier.\n",
    "\n",
    "- Column 1: `phrase ids` - Links to `phrase_id` in `dictionary.txt`\n",
    "- Column 2: `sentiment values` - Continuous sentiment score from 0 (most negative) to 1 (most positive)\n",
    "\n",
    "There are 5 sentiments (very negative, negative, neutral, positive, very positive) in original dataset, but this project only need binary classification (negative or positive), thus the sentences with sentiment values between 0.4 and 0.6 should be removed. Then convert labels to integers (0 or 1)\n",
    "\n",
    "```\n",
    "0.0 ←−−−−−−− 0.2 ←−−−− 0.4 ←− 0.5 −→ 0.6 −−−−→ 0.8 −−−−−−→ 1.0\n",
    "Very Negative | Negative | Neutral | Positive | Very Positive\n",
    "```\n",
    "---\n",
    "\n",
    "###  Final Format\n",
    "\n",
    "After processing, each DataFrame has this structure:\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| `sentence` | string | Movie review text |\n",
    "| `label` | int | Binary sentiment |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceefff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 11855\n",
      "Dictionary phrases: 239232\n",
      "Labels: 239232\n",
      "\n",
      "After filtering neutral samples: 9142\n",
      "Label distribution:\n",
      "label\n",
      "1    4739\n",
      "0    4403\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train: 6568, Val: 825, Test: 1749\n"
     ]
    }
   ],
   "source": [
    "# Load all sentences with their unique indices\n",
    "sentences_df = pd.read_csv('SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/datasetSentences.txt', sep='\\t', header=0)\n",
    "\n",
    "# Load dataset split assignments (train/dev/test)\n",
    "split_df = pd.read_csv('SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/datasetSplit.txt', sep=',', header=0)\n",
    "\n",
    "# Load phrase dictionary (maps phrases to unique IDs)\n",
    "dictionary_df = pd.read_csv('SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/dictionary.txt', sep='|', header=None, names=['phrase', 'phrase_id'])\n",
    "\n",
    "# Load sentiment labels for all phrases\n",
    "labels_df = pd.read_csv('SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/sentiment_labels.txt', sep='|', header=0)\n",
    "\n",
    "print(f\"Sentences: {len(sentences_df)}\")\n",
    "print(f\"Dictionary phrases: {len(dictionary_df)}\")\n",
    "print(f\"Labels: {len(labels_df)}\")\n",
    "\n",
    "# Combine sentences with their train/dev/test assignments\n",
    "data = sentences_df.merge(split_df, on='sentence_index')\n",
    "\n",
    "# Initialize empty dictionary to store sentence-to-label mappings\n",
    "sentence_labels = {}\n",
    "\n",
    "# Iterate through each sentence in the merged dataset\n",
    "for idx, row in data.iterrows():\n",
    "    sentence = row['sentence']  # Extract the sentence text\n",
    "    \n",
    "    # Look up phrase_id in dictionary\n",
    "    phrase_match = dictionary_df[dictionary_df['phrase'] == sentence]\n",
    "    \n",
    "    # Check if we found a match\n",
    "    if not phrase_match.empty:\n",
    "        # Extract the phrase_id for this sentence\n",
    "        phrase_id = phrase_match.iloc[0]['phrase_id']\n",
    "        \n",
    "        # Look up sentiment score using phrase_id\n",
    "        label_match = labels_df[labels_df['phrase ids'] == phrase_id]\n",
    "        \n",
    "        # Check if we found a sentiment score\n",
    "        if not label_match.empty:\n",
    "            # Extract the continuous sentiment value (0.0 to 1.0)\n",
    "            sentiment_value = label_match.iloc[0]['sentiment values']\n",
    "            \n",
    "            # Convert continuous sentiment to binary label\n",
    "            if sentiment_value <= 0.4:\n",
    "                # Negative class: very negative + negative samples\n",
    "                sentence_labels[sentence] = 0\n",
    "                \n",
    "            elif sentiment_value >= 0.6:\n",
    "                # Positive class: positive + very positive samples\n",
    "                sentence_labels[sentence] = 1\n",
    "\n",
    "# Apply Labels and Filter Neutral Samples, Map the sentence_labels dictionary to create a new 'label' column\n",
    "# Sentences not in sentence_labels (neutral samples) will have NaN values\n",
    "data['label'] = data['sentence'].map(sentence_labels)\n",
    "\n",
    "# Remove all rows where label is NaN\n",
    "data = data.dropna(subset=['label'])\n",
    "\n",
    "# Convert label column from float to integer type.\n",
    "data['label'] = data['label'].astype(int)\n",
    "\n",
    "# Display statistics after filtering\n",
    "print(f\"\\nAfter filtering neutral samples: {len(data)}\")\n",
    "print(f\"Label distribution:\\n{data['label'].value_counts()}\")\n",
    "\n",
    "# Training set (splitset_label == 1), keep only 'sentence' and 'label' columns, drop unnecessary columns\n",
    "train_df = data[data['splitset_label'] == 1][['sentence', 'label']].reset_index(drop=True)\n",
    "\n",
    "# Test set (splitset_label == 2)\n",
    "test_df = data[data['splitset_label'] == 2][['sentence', 'label']].reset_index(drop=True)\n",
    "\n",
    "# Validation/Development set (splitset_label == 3)\n",
    "val_df = data[data['splitset_label'] == 3][['sentence', 'label']].reset_index(drop=True)\n",
    "\n",
    "# Display final dataset sizes\n",
    "print(f\"\\nTrain: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730c14a",
   "metadata": {},
   "source": [
    "## Dataset processing\n",
    "\n",
    "This section transforms raw text data into numerical representations that neural networks can process. Text strings cannot be directly fed into neural networks - they must first be converted into sequences of integers.\n",
    "\n",
    "### Tokenization\n",
    "\n",
    "Split sentences into individual words and punctuation marks. Neural networks operate on discrete units. Also keep punctuation as separate tokens because they carry sentiment information\n",
    "\n",
    "### Vocabulary Construction\n",
    "\n",
    "Build a mapping between words and unique integer IDs (word → ID), a consistent way to convert any word into a number is required, including:\n",
    "\n",
    "- Filter rare words (frequency < 2): Reduces vocabulary size and filters potential typos/noise\n",
    "- Add special tokens: \n",
    "  - `<pad>`: For making sequences equal length (required for batch processing)\n",
    "  - `<unk>`: For handling words not seen during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ccf7c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 6864\n"
     ]
    }
   ],
   "source": [
    "# Breaking down text into individual words and punctuation marks\n",
    "_tok = re.compile(r\"\\w+|[^\\w\\s]\")\n",
    "def tokenize(s: str):\n",
    "    \"\"\"\n",
    "    Convert a sentence string into a list of lowercase tokens.\n",
    "    \"\"\"\n",
    "    return [t.lower() for t in _tok.findall(s)]\n",
    "\n",
    "# Define special tokens\n",
    "UNK = \"<unk>\"  # used for words not in vocabulary (out-of-vocabulary words)\n",
    "PAD = \"<pad>\"  # used to make all sequences the same length\n",
    "\n",
    "# Initialize a Counter to count word frequencies\n",
    "counter = Counter()\n",
    "\n",
    "# Count all words in the training set, only use training data to build vocabulary to prevent data leakage\n",
    "for sentence in train_df['sentence']:\n",
    "    # Tokenize each sentence and update word counts\n",
    "    counter.update(tokenize(sentence))\n",
    "# Build the vocabulary list\n",
    "itos = [PAD, UNK] + [w for w, c in counter.most_common() if c >= 2]\n",
    "# Build reverse mapping: string-to-index dictionary\n",
    "stoi = {w: i for i, w in enumerate(itos)}\n",
    "# Get the padding token's index\n",
    "padding_idx = stoi[PAD]\n",
    "# Calculate vocabulary size\n",
    "vocab_size = len(itos)\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e9258",
   "metadata": {},
   "source": [
    "## Loading Pre-trained Word Embeddings\n",
    "\n",
    "This code loads pre-trained GloVe embeddings and integrates them with the vocabulary. Instead of learning word representations from scratch, by leveraging embeddings trained on massive text corpora. Pre-trained embeddings significantly improve model performance, especially when training data is limited.\n",
    "\n",
    "Now have a `TEXT` object containing our vocabulary mappings (`itos`, `stoi`) and an embedding matrix where known words start with meaningful representations, giving our model a significant advantage before training even begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b8ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained GloVe (Global Vectors for Word Representation) embeddings\n",
    "glv = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "# Set the dimensionality of word embeddings to match GloVe's dimension\n",
    "embedding_dim = 100\n",
    "\n",
    "# Initialize a tensor to store embedding vectors for all vocabulary words\n",
    "pretrained_vectors = torch.randn(vocab_size, embedding_dim) * 0.01\n",
    "\n",
    "# Iterate through each token in the vocabulary\n",
    "for i, tok in enumerate(itos):\n",
    "    # Check if the current token exists in the pre-trained GloVe vocabulary\n",
    "    if tok in glv:\n",
    "        # If found, replace the random vector with the pre-trained GloVe vector\n",
    "        pretrained_vectors[i] = torch.tensor(glv[tok])\n",
    "\n",
    "# Set the embedding vector for the padding token to zeros\n",
    "pretrained_vectors[padding_idx] = 0.0\n",
    "\n",
    "# Create a namespace object to mimic the torchtext Field structure\n",
    "TEXT = types.SimpleNamespace(\n",
    "    vocab=types.SimpleNamespace(\n",
    "        itos=itos,                      # int-to-string: list mapping indices to tokens\n",
    "        stoi=stoi,                      # string-to-int: dict mapping tokens to indices\n",
    "        vectors=pretrained_vectors      # The embedding matrix with pre-trained vectors\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4111263b",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "This section implements a feature engineering pipeline to establish a baseline understanding of sentiment classification. First extract hand-crafted linguistic features and evaluate their predictive power. This approach helps us understand what signals are important for sentiment analysis.\n",
    "\n",
    "There are 7 hand-crafted features grouped into 4 categories, each capturing different aspects of sentiment expression:\n",
    "\n",
    "1. Length Features\n",
    "\n",
    "Text length can reflect sentiment strength - longer reviews might indicate stronger opinions (either very positive or very negative). Then normalize these features by dividing by typical values (50 tokens, 200 characters) to keep them in a reasonable range.\n",
    "\n",
    "2. Punctuation Features\n",
    "\n",
    "People expressing strong sentiment often use more emphatic punctuation.\n",
    "\n",
    "- Exclamation marks signal strong emotion (both positive and negative)\n",
    "- Question marks may indicate confusion or rhetorical emphasis\n",
    "- Commas suggest detailed, structured arguments\n",
    "\n",
    "3. Negation Features\n",
    "\n",
    "Negations are crucial for sentiment analysis because they reverse polarity. Then count common negation words like \"not\", \"no\", \"never\", and contractions like \"n't\", \"don't\", \"can't\". The count is normalized by the number of tokens.\n",
    "\n",
    "4. Intensifier Features\n",
    "\n",
    "Intensifiers amplify sentiment strength without changing its direction, these words indicate the author felt compelled to emphasize their sentiment, suggesting stronger opinions.\n",
    "\n",
    "### Feature Normalization Strategy\n",
    "\n",
    "All features are normalized to prevent scale imbalance. Without normalization, raw character counts (in the hundreds) would dominate small counts like intensifiers (0-2). the normalization approach:\n",
    "\n",
    "- Length features: Divided by typical text size (50 tokens, 200 chars)\n",
    "- Punctuation/word counts: Divided by total token count\n",
    "\n",
    "### Chi-Square Feature Importance Test\n",
    "\n",
    "The Chi-Square test measures the statistical dependency between each feature and the sentiment label. A high χ² score indicates a strong association between the feature and sentiment, suggesting the feature is informative for prediction. The p-value confirms whether this relationship is statistically significant.\n",
    "\n",
    "By examining χ² scores, we can identify which features are most predictive of sentiment and focus on the most informative signals.\n",
    "\n",
    "### Logistic Regression Baseline\n",
    "\n",
    "Use Logistic Regression as a simple baseline model. As a linear model, it learns explicit weights for each feature, allowing us to understand exactly how much each linguistic pattern contributes to sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477fe1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building feature validation dataset...\n",
      "Number of features: 7\n",
      "Training samples: 6568\n",
      "\n",
      "Feature Importance Ranking (Chi-square):\n",
      "           feature  chi2_score  p_value\n",
      "count_intensifiers    5.094269 0.024005\n",
      "    count_question    3.619379 0.057110\n",
      "   count_negations    3.596464 0.057903\n",
      "       count_comma    1.773648 0.182931\n",
      "     count_exclaim    1.730499 0.188347\n",
      "         len_chars    1.180790 0.277195\n",
      "        len_tokens    0.008274 0.927523\n",
      "\n",
      "LR Baseline validation accuracy: 0.5770\n",
      "Conclusion: Hand-crafted features alone achieve 57.7% classification ability\n",
      "Based on chi-square > 1.0, selected 6 features:\n",
      "   - count_intensifiers             (chi2=5.09)\n",
      "   - count_question                 (chi2=3.62)\n",
      "   - count_negations                (chi2=3.60)\n",
      "   - count_comma                    (chi2=1.77)\n",
      "   - count_exclaim                  (chi2=1.73)\n",
      "   - len_chars                      (chi2=1.18)\n"
     ]
    }
   ],
   "source": [
    "# Define common negation words that reverse sentiment\n",
    "NEGATIONS = {\"not\",\"no\",\"never\",\"n't\",\"dont\",\"don't\"}\n",
    "\n",
    "# Define intensifier words that amplify sentiment strength\n",
    "INTENSIFIERS = {\"very\",\"really\",\"so\",\"too\",\"extremely\"}\n",
    "\n",
    "# List of feature names we will extract\n",
    "FEATURE_NAMES = [\n",
    "    \"len_tokens\",           # Number of tokens in text\n",
    "    \"len_chars\",            # Total character count\n",
    "    \"count_exclaim\",        # Number of exclamation marks\n",
    "    \"count_question\",       # Number of question marks\n",
    "    \"count_comma\",          # Number of commas\n",
    "    \"count_negations\",      # Count of negation words\n",
    "    \"count_intensifiers\"    # Count of intensifier words\n",
    "]\n",
    "\n",
    "\n",
    "def extract_features(text):\n",
    "    \"\"\"\n",
    "    Extract simple features from text.\n",
    "    \"\"\"\n",
    "    # Tokenize text using regex pattern\n",
    "    tokens = _tok.findall(text)\n",
    "    # Convert all tokens to lowercase\n",
    "    tokens_lower = [t.lower() for t in tokens]\n",
    "    \n",
    "    # Count basic statistics\n",
    "    num_tokens = len(tokens)\n",
    "    num_chars = len(text)\n",
    "    \n",
    "    # Count punctuation marks\n",
    "    num_exclaim = text.count(\"!\")  # Count exclamation marks\n",
    "    num_question = text.count(\"?\")  # Count question marks\n",
    "    num_comma = text.count(\",\")  # Count commas\n",
    "    \n",
    "    # Count negation words in text\n",
    "    num_negations = sum(1 for t in tokens_lower if t in NEGATIONS)\n",
    "    \n",
    "    # Count intensifier words in text\n",
    "    num_intensifiers = sum(1 for t in tokens_lower if t in INTENSIFIERS)\n",
    "    \n",
    "    # Normalize features by text length\n",
    "    if num_tokens > 0:\n",
    "        features = {\n",
    "            \"len_tokens\": num_tokens / 50.0,  # Normalize by typical length\n",
    "            \"len_chars\": num_chars / 200.0,  # Normalize by typical char count\n",
    "            \"count_exclaim\": num_exclaim / num_tokens,  # Ratio of exclamation marks\n",
    "            \"count_question\": num_question / num_tokens,  # Ratio of question marks\n",
    "            \"count_comma\": num_comma / num_tokens,  # Ratio of commas\n",
    "            \"count_negations\": num_negations / num_tokens,  # Ratio of negations\n",
    "            \"count_intensifiers\": num_intensifiers / num_tokens  # Ratio of intensifiers\n",
    "        }\n",
    "    else:\n",
    "        # Handle empty text case\n",
    "        features = {name: 0.0 for name in FEATURE_NAMES}\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "print(\"Building feature validation dataset...\")\n",
    "train_features = []\n",
    "\n",
    "# Extract features from training data\n",
    "for idx, row in train_df.iterrows():\n",
    "    # Extract features from sentence\n",
    "    feats = extract_features(row['sentence']) \n",
    "    # Add label to feature dict\n",
    "    feats[\"label\"] = row['label']\n",
    "    # Add to list\n",
    "    train_features.append(feats)\n",
    "\n",
    "# Convert list of dicts to DataFrame\n",
    "df_features = pd.DataFrame(train_features)\n",
    "\n",
    "# Print dataset information\n",
    "print(f\"Number of features: {len(FEATURE_NAMES)}\")\n",
    "print(f\"Training samples: {len(df_features)}\")\n",
    "\n",
    "# Prepare data for chi-square test\n",
    "X_chi = df_features[FEATURE_NAMES].values\n",
    "y_chi = df_features[\"label\"].values\n",
    "\n",
    "# Calculate chi-square scores for each feature\n",
    "chi_scores, p_values = chi2(X_chi, y_chi)\n",
    "\n",
    "# Create ranking table with chi-square results\n",
    "chi_df = pd.DataFrame({\n",
    "    \"feature\": FEATURE_NAMES,\n",
    "    \"chi2_score\": chi_scores,\n",
    "    \"p_value\": p_values\n",
    "}).sort_values(\"chi2_score\", ascending=False)\n",
    "\n",
    "# Display feature importance ranking\n",
    "print(\"\\nFeature Importance Ranking (Chi-square):\")\n",
    "print(chi_df.to_string(index=False))\n",
    "\n",
    "# Extract features from validation data\n",
    "val_features = []\n",
    "for idx, row in val_df.iterrows():\n",
    "    feats = extract_features(row['sentence'])\n",
    "    feats[\"label\"] = row['label']\n",
    "    val_features.append(feats)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_val = pd.DataFrame(val_features)\n",
    "\n",
    "# Prepare train and validation data\n",
    "X_train_lr = df_features[FEATURE_NAMES].values  # Training features\n",
    "y_train_lr = df_features[\"label\"].values  # Training labels\n",
    "X_val_lr = df_val[FEATURE_NAMES].values  # Validation features\n",
    "y_val_lr = df_val[\"label\"].values  # Validation labels\n",
    "\n",
    "# Train logistic regression model\n",
    "lr_model = LogisticRegression(max_iter=500)\n",
    "lr_model.fit(X_train_lr, y_train_lr)\n",
    "\n",
    "# Evaluate model on validation set\n",
    "lr_pred = lr_model.predict(X_val_lr)\n",
    "lr_acc = accuracy_score(y_val_lr, lr_pred)\n",
    "\n",
    "# Print baseline results\n",
    "print(f\"\\nLR Baseline validation accuracy: {lr_acc:.4f}\")\n",
    "print(f\"Conclusion: Hand-crafted features alone achieve {lr_acc*100:.1f}% classification ability\")\n",
    "\n",
    "# Select features with chi-square score above threshold\n",
    "THRESHOLD = 1.0  # Set threshold for feature selection\n",
    "selected_features = chi_df[chi_df[\"chi2_score\"] > THRESHOLD][\"feature\"].tolist()\n",
    "\n",
    "# Print selected features\n",
    "print(f\"Based on chi-square > {THRESHOLD}, selected {len(selected_features)} features:\")\n",
    "for feat in selected_features:  # Loop through selected features\n",
    "    # Get chi-square value for this feature\n",
    "    chi_val = chi_df[chi_df[\"feature\"] == feat][\"chi2_score\"].values[0]\n",
    "    # Print feature name and chi-square score\n",
    "    print(f\"   - {feat:<30} (chi2={chi_val:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d4f34",
   "metadata": {},
   "source": [
    "## DataLoader Setup\n",
    "\n",
    "Create efficient data pipelines that feed batches of samples to the model during training.\n",
    "\n",
    "### Dataset Class\n",
    "\n",
    "Wrap preprocessed data in PyTorch's Dataset interface. PyTorch's DataLoader requires this structure for efficient batching and data loading\n",
    "\n",
    "This pipeline ensures our text data is properly prepared for the LSTM model while maintaining reproducibility and preventing data leakage.\n",
    "\n",
    "\n",
    "### Compute Numeric Feature Function\n",
    "\n",
    "The function processes batches of tokenized text in real-time, converting token IDs back to their string representations to analyze character-level patterns (punctuation, capitalization, emoticons) that aren't captured by word embeddings alone. These features are then normalized to comparable scales and concatenated with the neural network's learned representations, creating a richer input that combines learned semantic knowledge with explicit linguistic rules. In the neural network forward pass, this function is called to compute features for each batch.\n",
    "\n",
    "### Collate Function \n",
    "\n",
    "Sentences have variable lengths, but neural networks require fixed-size tensors. To address this, pad shorter sequences with special `<pad>` tokens to match the longest sequence in each batch\n",
    "\n",
    "### Training DataLoader\n",
    "- `shuffle=True`: Randomize sample order each epoch to prevent overfitting to data order, which is critical for good generalization\n",
    "\n",
    "- `batch_size=128`: Balance between speed and memory, 128 is a common choice for medium datasets\n",
    "\n",
    "### Validation/Test DataLoaders\n",
    "- `shuffle=False`: Keep fixed order to reproducible evaluation metrics\n",
    "\n",
    "- `pin_memory=True`: Speed up CPU→GPU transfer. Only beneficial when using MPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c62c293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes - Train: 6568, Val: 825, Test: 1749\n",
      "\n",
      "Batch info:\n",
      "Type: <class 'types.SimpleNamespace'>\n",
      "Text shape: torch.Size([128, 55])\n",
      "Label shape: torch.Size([128])\n",
      "Sample text (first 10 tokens): tensor([5264,  861,  105,    5,  543,  783,    7,  225,   15,    3])\n",
      "Sample label: 1\n"
     ]
    }
   ],
   "source": [
    "# Simple dataset class\n",
    "class SST2Dataset(Dataset):\n",
    "    def __init__(self, dataframe, stoi):\n",
    "        self.data = []\n",
    "        for _, row in dataframe.iterrows():\n",
    "            sentence = row['sentence']\n",
    "            label = int(row['label'])\n",
    "            # Convert words to IDs\n",
    "            ids = [stoi.get(w, stoi[UNK]) for w in tokenize(sentence)]\n",
    "            self.data.append({'input_ids': ids, 'label': label})\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "train_ds = SST2Dataset(train_df, stoi)\n",
    "val_ds = SST2Dataset(val_df, stoi)\n",
    "test_ds = SST2Dataset(test_df, stoi)\n",
    "\n",
    "print(f\"Dataset sizes - Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")\n",
    "\n",
    "\n",
    "# Extract features from text\n",
    "def compute_numeric_features(x_ids, pad_idx, selected_feat_names):\n",
    "    device = x_ids.device\n",
    "    B, T = x_ids.size()\n",
    "    feats_list = []\n",
    "    \n",
    "    for i in range(B):\n",
    "        # Get tokens\n",
    "        ids = x_ids[i].tolist()\n",
    "        ids = [t for t in ids if t != pad_idx]\n",
    "        toks = [TEXT.vocab.itos[t] for t in ids]\n",
    "        text = \" \".join(toks)\n",
    "        \n",
    "        # Count features\n",
    "        num_tokens = float(len(toks))\n",
    "        num_chars = float(len(text))\n",
    "        num_exclaim = float(text.count(\"!\"))\n",
    "        num_question = float(text.count(\"?\"))\n",
    "        num_comma = float(text.count(\",\"))\n",
    "        \n",
    "        # Count negations and intensifiers\n",
    "        toks_lower = [t.lower() for t in toks]\n",
    "        num_negations = float(sum(1 for t in toks_lower if t in NEGATIONS))\n",
    "        num_intensifiers = float(sum(1 for t in toks_lower if t in INTENSIFIERS))\n",
    "        \n",
    "        # Normalize features\n",
    "        if num_tokens > 0:\n",
    "            all_features = {\n",
    "                \"len_tokens\": num_tokens / 50.0,\n",
    "                \"len_chars\": num_chars / 200.0,\n",
    "                \"count_exclaim\": num_exclaim / num_tokens,\n",
    "                \"count_question\": num_question / num_tokens,\n",
    "                \"count_comma\": num_comma / num_tokens,\n",
    "                \"count_negations\": num_negations / num_tokens,\n",
    "                \"count_intensifiers\": num_intensifiers / num_tokens\n",
    "            }\n",
    "        else:\n",
    "            # Handle empty case\n",
    "            all_features = {fname: 0.0 for fname in selected_feat_names}\n",
    "        \n",
    "        # Get selected features\n",
    "        selected_vals = [all_features[fname] for fname in selected_feat_names]\n",
    "        feats_list.append(selected_vals)\n",
    "    \n",
    "    return torch.tensor(feats_list, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "# Collate function for batching\n",
    "def collate_fn(batch):\n",
    "    ids_list = []\n",
    "    labels = []\n",
    "    \n",
    "    for item in batch:\n",
    "        ids_list.append(item['input_ids'])\n",
    "        labels.append(item['label'])\n",
    "    \n",
    "    # Pad sequences to same length\n",
    "    max_len = max(len(x) for x in ids_list)\n",
    "    x = torch.full((len(ids_list), max_len), padding_idx, dtype=torch.long)\n",
    "    \n",
    "    for i, ids in enumerate(ids_list):\n",
    "        x[i, :len(ids)] = torch.tensor(ids, dtype=torch.long)\n",
    "    \n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    return types.SimpleNamespace(text=x, label=y)\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "train_iter = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
    "val_iter = DataLoader(val_ds, batch_size=128, shuffle=False, collate_fn=collate_fn)\n",
    "test_iter = DataLoader(test_ds, batch_size=128, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Check first batch\n",
    "first = next(iter(train_iter))\n",
    "print(f\"\\nBatch info:\")\n",
    "print(f\"Type: {type(first)}\")\n",
    "print(f\"Text shape: {first.text.shape}\")\n",
    "print(f\"Label shape: {first.label.shape}\")\n",
    "print(f\"Sample text (first 10 tokens): {first.text[0][:10]}\")\n",
    "print(f\"Sample label: {first.label[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b794b5e",
   "metadata": {},
   "source": [
    "## BiLSTM Classification Model\n",
    "\n",
    "\n",
    "I tried using LSTM, but the results were very poor. Thus, I employ a Bidirectional Long Short-Term Memory (BiLSTM) network as our primary algorithm. This choice is justified by following:\n",
    "\n",
    "1. Sequential Nature of Language: Text is not just a collection of random words—the order matters tremendously. LSTMs are designed specifically to process sequences where order matters. As the LSTM reads through a sentence word by word, it maintains a \"memory\" of what it has seen before. \n",
    "\n",
    "2. Long-Range Dependency Modeling: Sometimes the key to understanding sentiment is remembering something from much earlier in the text. RNNs  try to do this but fail because they forget information from earlier in the sequence. LSTMs solve this problem using special mechanisms called \"gates\" that act like memory controllers. \n",
    "\n",
    "3. Bidirectional Context Capture: A regular LSTM only reads left-to-right (forward). A Bidirectional LSTM  reading the sentence in both directions simultaneously: one LSTM reads left-to-right (forward), and another reads right-to-left (backward). By combining information from both directions, the model gets the complete picture, leading to much better understanding of sentiment.\n",
    "\n",
    "4. Hierarchical Representation Learning: We use 2 LSTM layers stacked on top of each other, which allows the model to learn patterns at different levels of abstraction. Our first LSTM layer learns basic patterns like grammar and simple word combinations. The second LSTM layer then takes these basic patterns and learns more complex, abstract patterns. \n",
    "\n",
    "### Metrics\n",
    "\n",
    "#### 1. Classification Accuracy\n",
    "\n",
    "We mainly use classification accuracy as our primary performance measure. \n",
    "\n",
    "Classification accuracy is the most appropriate metric for our sentiment analysis task. First, our dataset exhibits balanced class distribution—we have roughly equal numbers of positive and negative reviews, meaning accuracy won't be misleadingly inflated by predicting the majority class.\n",
    "\n",
    "Second, for binary sentiment classification, both classes (positive/negative) are equally important. We don't have an asymmetric cost structure where false positives are more costly than false negatives, so accuracy's equal weighting of all errors is appropriate.\n",
    "\n",
    "#### 2. Cross-Entropy Loss\n",
    "\n",
    "We also monitor cross-entropy loss during training and validation.\n",
    "\n",
    "Cross-entropy loss measures the divergence between predicted probability distributions and true labels, providing a more nuanced signal than accuracy during training. Cross-entropy rewards confident correct predictions and penalizes confident wrong predictions more heavily. \n",
    "\n",
    "Cross-entropy is the natural choice for neural network classification because it's the negative log-likelihood of the correct class, making it theoretically grounded in maximum likelihood estimation. It's also convex with respect to the final layer's logits, ensuring stable gradient descent optimization. \n",
    "\n",
    "### Overfitting and Underfitting Prevention\n",
    "\n",
    "#### 1. Overfitting Prevention\n",
    "\n",
    "1. Frozen Pretrained Embeddings: GloVe embeddings are pretrained on billions of words from Wikipedia and news corpora. These vectors already encode rich semantic relationships. By freezing these weights, we prevent the model from overfitting embeddings to our small training set (6,568 samples). \n",
    "\n",
    "\n",
    "2. Dropout Regularization: Dropout randomly sets activations to zero during training with probability `p`, forcing the network to learn redundant representations. If the model relies on a single neuron to detect \"not,\" and that neuron is dropped out 50% of the time, the model must learn alternative pathways to detect negation.\n",
    "\n",
    "3. Early Stopping with Model Checkpointing: Training for too many epochs inevitably leads to overfitting—the model continues improving on training data while validation performance degrades. Early stopping prevents this by monitoring validation loss and saving the model checkpoint when it achieves the lowest validation loss. After 50 epochs, even if the final model is overfit, we retain the best-performing model from earlier in training (typically around epochs 15-25).\n",
    "\n",
    "4. Train-Validation Monitoring: Explicit monitoring of the train-validation gap provides a human-interpretable diagnostic for model health. A gap of 2-5% is normal and acceptable—it indicates the model has learned patterns specific to training data but still generalizes well. A gap exceeding 10% signals severe overfitting, prompting us to stop training, increase regularization, or reduce model capacity.\n",
    "\n",
    "### 2. Underfitting Prevention\n",
    "\n",
    "1. Sufficient Model Capacity: 2-layer BiLSTM with 384 hidden units provides `384 × 2 directions × 2 layers = 1,536` hidden states across the network, sufficient to learn nuanced linguistic patterns.\n",
    "\n",
    "2. Adequate Training Duration: Training for 50 epochs with early stopping ensures we explore enough of the loss landscape. If validation loss is still decreasing at epoch 50, we'd extend training, but typically loss plateaus around epoch 20-30.\n",
    "\n",
    "3. High Initial Learning Rate: Starting with LR=0.15 ensures rapid initial learning. Too small a learning rate (e.g., 0.001) would cause extremely slow convergence, potentially getting stuck in poor local minima and resulting in underfitting.\n",
    "\n",
    "4. Monitoring Training Loss: If training loss remains high (>0.5) throughout training, this signals underfitting—the model lacks capacity or training time to fit the data. We'd respond by adding layers, or training longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7edd5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration:\n",
      "Vocabulary size: 6864\n",
      "Embedding dimension: 100\n",
      "Hidden dimension: 256\n",
      "Number of features: 6\n",
      "\n",
      "Starting training...\n",
      "Epoch 10: Train Loss=0.671, Val Loss=0.661\n",
      "  Train Acc=0.608, Val Acc=0.630\n",
      "Epoch 20: Train Loss=0.603, Val Loss=0.562\n",
      "  Train Acc=0.687, Val Acc=0.691\n",
      "Epoch 30: Train Loss=0.537, Val Loss=0.517\n",
      "  Train Acc=0.767, Val Acc=0.765\n",
      "Epoch 40: Train Loss=0.511, Val Loss=0.552\n",
      "  Train Acc=0.756, Val Acc=0.743\n",
      "Epoch 50: Train Loss=0.502, Val Loss=0.471\n",
      "  Train Acc=0.771, Val Acc=0.783\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 256  # hidden dimension for LSTM\n",
    "label_size = 2  # binary classification\n",
    "num_features = len(selected_features)  # number of hand-crafted features\n",
    "\n",
    "# Print model configuration\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "print(f\"Hidden dimension: {hidden_dim}\")\n",
    "print(f\"Number of features: {num_features}\")\n",
    "\n",
    "\n",
    "# Define BiLSTM classifier\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size, padding_idx, num_features, feat_names):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        # Create embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        # Load pretrained word vectors\n",
    "        self.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "        # Freeze embedding weights\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        # Create bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Feature projection layer\n",
    "        self.feat_layer = nn.Linear(num_features, 32)\n",
    "        # Final classification layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2 + 32, output_size)\n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Store padding index\n",
    "        self.pad_idx = padding_idx\n",
    "        # Store feature names\n",
    "        self.feat_names = feat_names\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get word embeddings\n",
    "        embedded = self.embedding(x)\n",
    "        # Apply dropout\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # Pass through LSTM\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        # Concatenate forward and backward hidden states\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        \n",
    "        # Extract hand-crafted features\n",
    "        features = compute_numeric_features(x, self.pad_idx, self.feat_names)\n",
    "        # Project features\n",
    "        features = self.feat_layer(features)\n",
    "        \n",
    "        # Combine LSTM output and features\n",
    "        combined = torch.cat([hidden, features], dim=1)\n",
    "        # Get final prediction\n",
    "        out = self.fc(combined)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = BiLSTMClassifier(vocab_size, embedding_dim, hidden_dim, label_size, padding_idx, num_features, selected_features)\n",
    "# Move model to device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Set initial learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Training function\n",
    "def train_model(model, data_loader, criterion, lr):\n",
    "    model.train()  # set model to training mode\n",
    "    total_loss = 0  # initialize total loss\n",
    "    \n",
    "    # Loop through batches\n",
    "    for batch in data_loader:\n",
    "        # Get input and labels\n",
    "        x = batch.text.to(device)\n",
    "        y = batch.label.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(x)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Manual parameter update\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                if param.grad is not None:  # check if gradient exists\n",
    "                    param.data = param.data - lr * param.grad  # update weights\n",
    "                    param.grad.zero_()  # reset gradients\n",
    "        \n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Return average loss\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def eval_model(model, data_loader, criterion):\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    total_loss = 0  # initialize total loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            # Get input and labels\n",
    "            x = batch.text.to(device)\n",
    "            y = batch.label.to(device)\n",
    "            # Forward pass\n",
    "            output = model(x)\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, y)\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    # Return average loss\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def get_accuracy(model, data_loader):\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    correct = 0  # count of correct predictions\n",
    "    total = 0  # total number of samples\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            # Get input and labels\n",
    "            x = batch.text.to(device)\n",
    "            y = batch.label.to(device)\n",
    "            # Forward pass\n",
    "            output = model(x)\n",
    "            # Get predicted class\n",
    "            _, pred = torch.max(output, 1)\n",
    "            # Update total count\n",
    "            total += y.size(0)\n",
    "            # Update correct count\n",
    "            correct += (pred == y).sum().item()\n",
    "    \n",
    "    # Return accuracy\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# Set number of epochs\n",
    "epochs = 50\n",
    "# Initialize best loss\n",
    "best_loss = 999999\n",
    "\n",
    "# Lists to store metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "# Start training\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Train for one epoch\n",
    "    train_loss = train_model(model, train_iter, criterion, learning_rate)\n",
    "    # Evaluate on validation set\n",
    "    val_loss = eval_model(model, val_iter, criterion)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_acc = get_accuracy(model, train_iter)\n",
    "    val_acc = get_accuracy(model, val_iter)\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "    \n",
    "    # Reduce learning rate every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        learning_rate = learning_rate * 0.8 \n",
    "    \n",
    "    # Print progress every 5 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}: Train Loss={train_loss:.3f}, Val Loss={val_loss:.3f}')\n",
    "        print(f'  Train Acc={train_acc:.3f}, Val Acc={val_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb48e6",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "After training for 50 epochs, we evaluated our BiLSTM model against a logistic regression baseline to assess the effectiveness of deep learning combined with feature fusion for sentiment classification.\n",
    "\n",
    "- Logistic Regression Baseline: 57.70%\n",
    "- BiLSTM + Feature Fusion (Validation): 78.67%\n",
    "- BiLSTM + Feature Fusion (Test): 78.39%\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "1. This BiLSTM model with feature fusion achieved 78.39% accuracy on the test set, representing a 20.69% improvement over the logistic regression baseline. This substantial gain demonstrates that deep learning can capture complex linguistic patterns that simple linear models cannot.\n",
    "\n",
    "2. The logistic regression baseline, using only hand-crafted features, achieved 57.70% accuracy—significantly better than random guessing (50%). This validates that our carefully designed linguistic features contain meaningful sentiment signals.\n",
    "\n",
    "3. The small gap between validation accuracy (78.67%) and test accuracy (78.39%)—only 0.28%—indicates our model generalizes well to unseen data. This minimal difference suggests we successfully prevented overfitting through our regularization strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a699d800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Comparison:\n",
      "  Logistic Regression Baseline:  0.5770\n",
      "  BiLSTM + Feature Fusion (val): 0.7867\n",
      "  BiLSTM + Feature Fusion (test):0.7839\n",
      "Summary:\n",
      "  1. Feature Validation: LR baseline 0.5770\n",
      "  2. Deep Model: BiLSTM with feature fusion achieved 0.7839\n"
     ]
    }
   ],
   "source": [
    "test_acc = get_accuracy(best_model, test_iter)\n",
    "\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(f\"  Logistic Regression Baseline:  {lr_acc:.4f}\")\n",
    "print(f\"  BiLSTM + Feature Fusion (val): {max(val_accs):.4f}\")\n",
    "print(f\"  BiLSTM + Feature Fusion (test):{test_acc:.4f}\")\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(f\"  1. Feature Validation: LR baseline {lr_acc:.4f}\")\n",
    "print(f\"  2. Deep Model: BiLSTM with feature fusion achieved {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
