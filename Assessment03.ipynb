{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e7ca99",
   "metadata": {},
   "source": [
    "## Device initialization\n",
    "\n",
    "This section initializes the computational environment for the project. It performs three critical tasks:\n",
    "\n",
    "1. Detects available hardware (CPU vs GPU)\n",
    "2. Configures PyTorch to use the optimal compute device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832fc9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is mps available? True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Data manipulation and analysis.\n",
    "import numpy as np # Numerical operations and array handling.\n",
    "import matplotlib.pyplot as plt # More control, lower-level, basic plotting.\n",
    "import seaborn as sns # Higher-level, more aesthetically pleasing plots.\n",
    "from scipy import stats # Statistical functions and tests.\n",
    "\n",
    "pd.set_option('display.max_columns', None) # Display all columns in DataFrame output.\n",
    "pd.set_option('display.max_rows', None) # Display all rows in DataFrame output.\n",
    "\n",
    "import torch\n",
    "import types\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "import copy\n",
    "\n",
    "# Check if MPS is available for acceleration\n",
    "print('is mps available?', torch.mps.is_available())\n",
    "\n",
    "# Set the device to MPS if available, otherwise use CPU\n",
    "device = torch.device('mps' if torch.mps.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2e7ce",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "\n",
    "This section loads the SST dataset from local files and processes it for binary sentiment classification.\n",
    "\n",
    "4 files are loaded from the `SST2-Data/stanfordSentimentTreebank/` folder:\n",
    "\n",
    "### 1. `datasetSentences.txt`\n",
    "\n",
    "Contains all sentences extracted from movie reviews, this is the primary data source containing the text we want to classify.\n",
    "\n",
    "- Column 1: `sentence_index` - Unique identifier for each sentence\n",
    "- Column 2: `sentence` - The actual text of the sentence\n",
    "\n",
    "### 2. `datasetSplit.txt`\n",
    "\n",
    "Specifies which dataset split each sentence belongs to, ensures using the standard train/dev/test splits.\n",
    "\n",
    "- Column 1: `sentence_index` - Links to sentences in `datasetSentences.txt`\n",
    "- Column 2: `splitset_label` - Split assignment\n",
    "  - **1** = Training set\n",
    "  - **2** = Test set\n",
    "  - **3** = Development/Validation set\n",
    "\n",
    "### 3. `dictionary.txt`\n",
    "\n",
    "Maps all phrases (including sub-phrases) to unique IDs, acts as a lookup table to connect sentences to their sentiment labels, as a bridge between `datasetSentences.txt` and `sentiment_labels.txt`.\n",
    "\n",
    "- Column 1: `phrase` - Text of the phrase (can be a word, sub-phrase, or complete sentence)\n",
    "- Column 2: `phrase_id` - Unique integer identifier\n",
    "\n",
    "### 4. `sentiment_labels.txt`\n",
    "\n",
    "Contains sentiment scores for all phrases, provides the ground truth labels for training our sentiment classifier.\n",
    "\n",
    "- Column 1: `phrase ids` - Links to `phrase_id` in `dictionary.txt`\n",
    "- Column 2: `sentiment values` - Continuous sentiment score from 0 (most negative) to 1 (most positive)\n",
    "\n",
    "There are 5 sentiments (very negative, negative, neutral, positive, very positive) in original dataset, but this project we only need binary classification (negative or positive), thus the sentences with sentiment values between 0.4 and 0.6 should be removed. Then convert labels to integers (0 or 1)\n",
    "\n",
    "```\n",
    "0.0 ←−−−−−−− 0.2 ←−−−− 0.4 ←− 0.5 −→ 0.6 −−−−→ 0.8 −−−−−−→ 1.0\n",
    "Very Negative | Negative | Neutral | Positive | Very Positive\n",
    "```\n",
    "---\n",
    "\n",
    "###  Final Format\n",
    "\n",
    "After processing, each DataFrame has this structure:\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| `sentence` | string | Movie review text |\n",
    "| `label` | int | Binary sentiment |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceefff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences: 11855\n",
      "Dictionary phrases: 239232\n",
      "Labels: 239232\n",
      "\n",
      "After filtering neutral samples: 9142\n",
      "Label distribution:\n",
      "label\n",
      "1    4739\n",
      "0    4403\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train: 6568, Val: 825, Test: 1749\n"
     ]
    }
   ],
   "source": [
    "# Load all sentences with their unique indices\n",
    "sentences_df = pd.read_csv('SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/datasetSentences.txt', sep='\\t', header=0)\n",
    "\n",
    "# Load dataset split assignments (train/dev/test)\n",
    "split_df = pd.read_csv('SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/datasetSplit.txt', sep=',', header=0)\n",
    "\n",
    "# Load phrase dictionary (maps phrases to unique IDs)\n",
    "dictionary_df = pd.read_csv('SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/dictionary.txt', sep='|', header=None, names=['phrase', 'phrase_id'])\n",
    "\n",
    "# Load sentiment labels for all phrases\n",
    "labels_df = pd.read_csv('SST2-Data/stanfordSentimentTreebank/stanfordSentimentTreebank/sentiment_labels.txt', sep='|', header=0)\n",
    "\n",
    "print(f\"Sentences: {len(sentences_df)}\")\n",
    "print(f\"Dictionary phrases: {len(dictionary_df)}\")\n",
    "print(f\"Labels: {len(labels_df)}\")\n",
    "\n",
    "# Combine sentences with their train/dev/test assignments\n",
    "data = sentences_df.merge(split_df, on='sentence_index')\n",
    "\n",
    "# Initialize empty dictionary to store sentence-to-label mappings\n",
    "sentence_labels = {}\n",
    "\n",
    "# Iterate through each sentence in the merged dataset\n",
    "for idx, row in data.iterrows():\n",
    "    sentence = row['sentence']  # Extract the sentence text\n",
    "    \n",
    "    # Look up phrase_id in dictionary\n",
    "    phrase_match = dictionary_df[dictionary_df['phrase'] == sentence]\n",
    "    \n",
    "    # Check if we found a match\n",
    "    if not phrase_match.empty:\n",
    "        # Extract the phrase_id for this sentence\n",
    "        phrase_id = phrase_match.iloc[0]['phrase_id']\n",
    "        \n",
    "        # Look up sentiment score using phrase_id\n",
    "        label_match = labels_df[labels_df['phrase ids'] == phrase_id]\n",
    "        \n",
    "        # Check if we found a sentiment score\n",
    "        if not label_match.empty:\n",
    "            # Extract the continuous sentiment value (0.0 to 1.0)\n",
    "            sentiment_value = label_match.iloc[0]['sentiment values']\n",
    "            \n",
    "            # Convert continuous sentiment to binary label\n",
    "            if sentiment_value <= 0.4:\n",
    "                # Negative class: very negative + negative samples\n",
    "                sentence_labels[sentence] = 0\n",
    "                \n",
    "            elif sentiment_value >= 0.6:\n",
    "                # Positive class: positive + very positive samples\n",
    "                sentence_labels[sentence] = 1\n",
    "\n",
    "# Apply Labels and Filter Neutral Samples, Map the sentence_labels dictionary to create a new 'label' column\n",
    "# Sentences not in sentence_labels (neutral samples) will have NaN values\n",
    "data['label'] = data['sentence'].map(sentence_labels)\n",
    "\n",
    "# Remove all rows where label is NaN\n",
    "data = data.dropna(subset=['label'])\n",
    "\n",
    "# Convert label column from float to integer type.\n",
    "data['label'] = data['label'].astype(int)\n",
    "\n",
    "# Display statistics after filtering\n",
    "print(f\"\\nAfter filtering neutral samples: {len(data)}\")\n",
    "print(f\"Label distribution:\\n{data['label'].value_counts()}\")\n",
    "\n",
    "# Training set (splitset_label == 1), keep only 'sentence' and 'label' columns, drop unnecessary columns\n",
    "train_df = data[data['splitset_label'] == 1][['sentence', 'label']].reset_index(drop=True)\n",
    "\n",
    "# Test set (splitset_label == 2)\n",
    "test_df = data[data['splitset_label'] == 2][['sentence', 'label']].reset_index(drop=True)\n",
    "\n",
    "# Validation/Development set (splitset_label == 3)\n",
    "val_df = data[data['splitset_label'] == 3][['sentence', 'label']].reset_index(drop=True)\n",
    "\n",
    "# Display final dataset sizes\n",
    "print(f\"\\nTrain: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730c14a",
   "metadata": {},
   "source": [
    "## Dataset processing\n",
    "\n",
    "This section transforms raw text data into numerical representations that neural networks can process. Text strings cannot be directly fed into neural networks - they must first be converted into sequences of integers.\n",
    "\n",
    "### Tokenization\n",
    "\n",
    "Split sentences into individual words and punctuation marks. Neural networks operate on discrete units. We also keep punctuation as separate tokens because they carry sentiment information\n",
    "\n",
    "### Vocabulary Construction\n",
    "\n",
    "Build a mapping between words and unique integer IDs (word → ID), a consistent way to convert any word into a number is required, including:\n",
    "\n",
    "- Filter rare words (frequency < 2): Reduces vocabulary size and filters potential typos/noise\n",
    "- Add special tokens: \n",
    "  - `<pad>`: For making sequences equal length (required for batch processing)\n",
    "  - `<unk>`: For handling words not seen during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ccf7c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 6864\n"
     ]
    }
   ],
   "source": [
    "# Tokenization: Breaking down text into individual words and punctuation marks\n",
    "_tok = re.compile(r\"\\w+|[^\\w\\s]\")\n",
    "def tokenize(s: str):\n",
    "    \"\"\"\n",
    "    Convert a sentence string into a list of lowercase tokens.\n",
    "    \"\"\"\n",
    "    return [t.lower() for t in _tok.findall(s)]\n",
    "\n",
    "# Define special tokens\n",
    "UNK = \"<unk>\"  # Unknown token: used for words not in vocabulary (out-of-vocabulary words)\n",
    "PAD = \"<pad>\"  # Padding token: used to make all sequences the same length\n",
    "\n",
    "# Initialize a Counter to count word frequencies\n",
    "counter = Counter()\n",
    "\n",
    "# Count all words in the training set, only use training data to build vocabulary to prevent data leakage\n",
    "for sentence in train_df['sentence']:\n",
    "    # Tokenize each sentence and update word counts\n",
    "    counter.update(tokenize(sentence))\n",
    "# Build the vocabulary list\n",
    "itos = [PAD, UNK] + [w for w, c in counter.most_common() if c >= 2]\n",
    "# Build reverse mapping: string-to-index dictionary\n",
    "stoi = {w: i for i, w in enumerate(itos)}\n",
    "# Get the padding token's index\n",
    "padding_idx = stoi[PAD]\n",
    "# Calculate vocabulary size\n",
    "vocab_size = len(itos)\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e9258",
   "metadata": {},
   "source": [
    "## Loading Pre-trained Word Embeddings\n",
    "\n",
    "This code loads pre-trained GloVe embeddings and integrates them with our vocabulary. Instead of learning word representations from scratch, we leverage embeddings trained on massive text corpora. Pre-trained embeddings significantly improve model performance, especially when training data is limited.\n",
    "\n",
    "We now have a `TEXT` object containing our vocabulary mappings (`itos`, `stoi`) and an embedding matrix where known words start with meaningful representations, giving our model a significant advantage before training even begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b8ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the gensim downloader API for accessing pre-trained word embeddings\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load pre-trained GloVe (Global Vectors for Word Representation) embeddings\n",
    "glv = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "# Set the dimensionality of word embeddings to match GloVe's dimension\n",
    "embedding_dim = 100\n",
    "\n",
    "# Initialize a tensor to store embedding vectors for all vocabulary words\n",
    "pretrained_vectors = torch.randn(vocab_size, embedding_dim) * 0.01\n",
    "\n",
    "# Iterate through each token in the vocabulary\n",
    "for i, tok in enumerate(itos):\n",
    "    # Check if the current token exists in the pre-trained GloVe vocabulary\n",
    "    if tok in glv:\n",
    "        # If found, replace the random vector with the pre-trained GloVe vector\n",
    "        pretrained_vectors[i] = torch.tensor(glv[tok])\n",
    "\n",
    "# Set the embedding vector for the padding token to zeros\n",
    "pretrained_vectors[padding_idx] = 0.0\n",
    "\n",
    "# Create a namespace object to mimic the torchtext Field structure\n",
    "TEXT = types.SimpleNamespace(\n",
    "    vocab=types.SimpleNamespace(\n",
    "        itos=itos,                      # int-to-string: list mapping indices to tokens\n",
    "        stoi=stoi,                      # string-to-int: dict mapping tokens to indices\n",
    "        vectors=pretrained_vectors      # The embedding matrix with pre-trained vectors\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4111263b",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "This section implements a feature engineering pipeline to establish a baseline understanding of sentiment classification. First extract hand-crafted linguistic features and evaluate their predictive power. This approach helps us understand what signals are important for sentiment analysis.\n",
    "\n",
    "There are 15 hand-crafted features extracted grouped into 7 categories, each capturing different aspects of sentiment expression:\n",
    "\n",
    "1. Length Features (Text Complexity)\n",
    "\n",
    "```python\n",
    "- len_tokens: Number of word tokens\n",
    "- len_chars: Total character count  \n",
    "- avg_tok_len: Average token length\n",
    "```\n",
    "\n",
    "- Positive reviews might be longer (detailed praise) or negative reviews might be longer (detailed complaints)\n",
    "- Longer words may indicate more formal or complex language\n",
    "- Text length reflects how much the author cared to express\n",
    "\n",
    "2. Punctuation Features (Emotional Expression)\n",
    "\n",
    "People expressing strong sentiment use more emphatic punctuation.\n",
    "\n",
    "```python\n",
    "- count_exclaim: '!' count (excitement/emphasis)\n",
    "- count_question: '?' count (uncertainty/questioning)\n",
    "- count_period: '.' count (sentence structure)\n",
    "- count_comma: ',' count (clause complexity)\n",
    "- count_punct_total: Overall punctuation density\n",
    "```\n",
    "\n",
    "- Exclamation marks signal strong emotion (both positive and negative)\n",
    "- Question marks often indicate confusion, doubt, or rhetorical emphasis\n",
    "- Commas suggest detailed, structured arguments (common in thoughtful reviews)\n",
    "- Punctuation density reflects writing style and emotional intensity\n",
    "\n",
    "3. Uppercase Features (Emphasis/Shouting)\n",
    "\n",
    "```python\n",
    "- count_upper_tokens: Number of ALL CAPS words\n",
    "- ratio_upper_tokens: Proportion of text in caps\n",
    "```\n",
    "\n",
    "- ALL CAPS = SHOUTING or EMPHASIS\n",
    "- Strong indicator of emotional intensity\n",
    "\n",
    "4. Elongation Features (Informal Emphasis)\n",
    "\n",
    "Character elongation mimics prosody (speech intonation) in written text.\n",
    "\n",
    "```python\n",
    "- count_elongated: Words with repeated characters\n",
    "```\n",
    "\n",
    "- Informal emphasis technique common in social media and reviews\n",
    "- Strong sentiment indicator: Positive: \"This is soooo good!\" Negative: \"Soooo disappointed\"\n",
    "\n",
    "---\n",
    "\n",
    "5. Negation Features (Sentiment Reversal)\n",
    "\n",
    "Simple bag-of-words models fail on negations - this feature explicitly captures them.\n",
    "\n",
    "```python\n",
    "- count_negations: Negation words (not, no, never, don't, can't, etc.)\n",
    "```\n",
    "\n",
    "- Negations reverse polarity: \"good\" → positive, \"not good\" → negative\n",
    "- Negations interact with surrounding words to flip meaning\n",
    "- High negation count may indicate negative sentiment (\"not good\", \"don't like\", \"never again\")\n",
    "\n",
    "6. Intensifier Features (Sentiment Amplification)\n",
    "\n",
    "Intensifiers modify adjectives to increase subjective intensity.\n",
    "\n",
    "```python\n",
    "- count_intensifiers: Intensifying adverbs (very, really, extremely, incredibly)\n",
    "```\n",
    "\n",
    "- Amplify sentiment strength without changing polarity\n",
    "- Indicate strong opinions and emotional engagement\n",
    "- Presence suggests the author felt compelled to emphasize their sentiment\n",
    "\n",
    "7. Emoticon Features (Direct Sentiment Signals)\n",
    "\n",
    "Emoticons serve as digital paralanguage, conveying emotion that would be expressed through facial expressions in person.\n",
    "\n",
    "```python\n",
    "- count_pos_emotes: Positive emoticons (:), :D, ^^)\n",
    "- count_neg_emotes: Negative emoticons (:(, :/, :'()\n",
    "```\n",
    "\n",
    "- Unambiguous sentiment indicators - direct emotional expression\n",
    "- Common in informal text (social media, casual reviews)\n",
    "- Often used to clarify tone: \"This is great :)\" vs. \"This is great :/\"\n",
    "\n",
    "### Feature Normalization Strategy\n",
    "\n",
    "All features are normalized to prevent scale imbalance:\n",
    "\n",
    "- Raw character count (100s) would overwhelm emoticon count (0-2)\n",
    "- A text with 100 tokens and 5 exclamations is different from 10 tokens and 5 exclamations\n",
    "\n",
    "using flowing methods:\n",
    "\n",
    "- Length features → Scaled by typical text size\n",
    "- Punctuation → Divided by token or character count\n",
    "- Ratios → Already normalized\n",
    "- Emoticons → Raw counts\n",
    "\n",
    "### Chi-Square Feature Importance Test\n",
    "\n",
    "The Chi-Square test measures the statistical dependency between each feature and the sentiment label. A high χ² score indicates a strong association between the feature and sentiment, suggesting the feature is informative for prediction. Additionally, a low p-value confirms that this relationship is statistically significant and not due to random chance. \n",
    "\n",
    "We can keep features with high χ² scores (strong predictors) and discard those with low scores (weak or redundant predictors), ensuring our model focuses on the most informative signals while reducing noise and dimensionality.\n",
    "\n",
    "### Logistic Regression Baseline\n",
    "\n",
    "Logistic Regression serves as a linear model, it learns explicit weights for each feature, allowing us to understand exactly how much each linguistic pattern contributes to sentiment prediction. This transparency is valuable for validating our feature engineering decisions and building intuition about what matters for sentiment classification. \n",
    "\n",
    "An accuracy of 70-75% indicates that our hand-crafted features successfully capture significant sentiment signals, validating our feature engineering approach while leaving room for more sophisticated models to improve. If accuracy falls between 50-60%, it suggests our features are too weak and that we need representation learning techniques (like word embeddings and neural networks) to extract deeper semantic patterns. Conversely, if accuracy exceeds 80%, it may indicate that the classification problem is relatively simple, the dataset is small or homogeneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477fe1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building feature validation dataset...\n",
      "Number of features: 15\n",
      "Training samples: 6568\n",
      "\n",
      "Feature Importance Ranking (Chi-square):\n",
      "                feature  chi2_score  p_value\n",
      "   count_negations_norm   11.013588 0.000904\n",
      "count_intensifiers_norm    5.073290 0.024297\n",
      "    count_question_norm    4.994573 0.025427\n",
      "     count_exclaim_norm    3.474562 0.062319\n",
      "         len_chars_norm    2.561395 0.109502\n",
      "       count_comma_norm    2.267597 0.132105\n",
      "      count_period_norm    1.148853 0.283789\n",
      "       avg_tok_len_norm    1.024558 0.311440\n",
      "count_upper_tokens_norm    1.018557 0.312862\n",
      "ratio_upper_tokens_norm    0.509278 0.475451\n",
      " count_punct_total_norm    0.328244 0.566695\n",
      "   count_elongated_norm    0.266407 0.605752\n",
      "        len_tokens_norm    0.000239 0.987673\n",
      "  count_pos_emotes_norm         NaN      NaN\n",
      "  count_neg_emotes_norm         NaN      NaN\n",
      "\n",
      "LR Baseline validation accuracy: 0.5952\n",
      "Conclusion: Hand-crafted features alone achieve 59.5% classification ability\n",
      "Based on chi-square > 1.0, selected 9 features:\n",
      "   - count_negations_norm           (chi2=11.01)\n",
      "   - count_intensifiers_norm        (chi2=5.07)\n",
      "   - count_question_norm            (chi2=4.99)\n",
      "   - count_exclaim_norm             (chi2=3.47)\n",
      "   - len_chars_norm                 (chi2=2.56)\n",
      "   - count_comma_norm               (chi2=2.27)\n",
      "   - count_period_norm              (chi2=1.15)\n",
      "   - avg_tok_len_norm               (chi2=1.02)\n",
      "   - count_upper_tokens_norm        (chi2=1.02)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score          # Metric to evaluate classification accuracy\n",
    "from sklearn.discriminant_analysis import StandardScaler  # Feature normalization (z-score scaling)\n",
    "from sklearn.feature_selection import chi2       # Chi-square test for feature importance\n",
    "from sklearn.linear_model import LogisticRegression  # Simple linear classifier as baseline\n",
    "\n",
    "# Words that negate or reverse sentiment (e.g., \"not good\" becomes negative)\n",
    "NEGATIONS = {\"not\",\"no\",\"never\",\"n't\",\"dont\",\"don't\",\"didn't\",\"won't\",\"cannot\",\"can't\"}\n",
    "\n",
    "# Words that amplify sentiment intensity (e.g., \"very good\" is stronger than \"good\")\n",
    "INTENSIFIERS = {\"very\",\"really\",\"so\",\"too\",\"extremely\",\"super\",\"highly\",\"utterly\",\"absolutely\",\"incredibly\"}\n",
    "\n",
    "# Emoticons indicating positive sentiment\n",
    "POS_EMOTES = [\":)\",\":-)\",\":d\",\"=)\",\":]\",\"^^\"]\n",
    "\n",
    "# Emoticons indicating negative sentiment\n",
    "NEG_EMOTES = [\":(\",\" :-(\",\" ):\",\":'(\",\" :/ \",\":-/\"]\n",
    "\n",
    "\n",
    "# These features capture linguistic patterns that correlate with sentiment\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"len_tokens\",           # Number of word tokens (vocabulary richness)\n",
    "    \"len_chars\",            # Total character count (text verbosity)\n",
    "    \"avg_tok_len\",          # Average token length (word complexity)\n",
    "    \n",
    "    \"count_exclaim\",        # '!' count (excitement/emphasis indicator)\n",
    "    \"count_question\",       # '?' count (questioning/uncertainty)\n",
    "    \"count_period\",         # '.' count (sentence structure)\n",
    "    \"count_comma\",          # ',' count (clause complexity)\n",
    "    \"count_punct_total\",    # Total punctuation (stylistic density)\n",
    "    \n",
    "    \"count_upper_tokens\",   # ALL CAPS words (shouting/emphasis)\n",
    "    \"ratio_upper_tokens\",   # Proportion of uppercase tokens\n",
    "    \n",
    "    \"count_elongated\",      # Words with repeated letters (e.g., \"soooo good\")\n",
    "    \"count_negations\",      # Negation words (sentiment reversal)\n",
    "    \"count_intensifiers\",   # Intensifier words (sentiment amplification)\n",
    "    \n",
    "    \"count_pos_emotes\",     # Positive emoticon count\n",
    "    \"count_neg_emotes\"      # Negative emoticon count\n",
    "]\n",
    "\n",
    "\n",
    "def is_all_caps_token(tok: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a token is written in ALL CAPS.\n",
    "    \"\"\"\n",
    "    # Extract only alphabetic characters\n",
    "    letters = [ch for ch in tok if ch.isalpha()]\n",
    "    # Require at least 2 letters and all must be uppercase\n",
    "    return (len(letters) >= 2) and all(ch.isupper() for ch in letters)\n",
    "\n",
    "\n",
    "def compute_features_for_text(text: str):\n",
    "    \"\"\"\n",
    "    Extract hand-crafted linguistic features from text for sentiment analysis.\n",
    "    \"\"\"\n",
    "    # Tokenize text using pre-defined tokenizer pattern\n",
    "    toks = _tok.findall(text)\n",
    "    toks_lower = [t.lower() for t in toks]\n",
    "    \n",
    "    # Filter to word tokens (containing at least one letter)\n",
    "    word_tokens = [t for t in toks if any(ch.isalpha() for ch in t)]\n",
    "    T = len(word_tokens)  # Total number of word tokens\n",
    "    L = len(text)         # Total character length\n",
    "    \n",
    "    # Punctuation features: Capture emotional expression through punctuation\n",
    "    count_exclaim = text.count(\"!\")        # Excitement/emphasis\n",
    "    count_question = text.count(\"?\")       # Questions/uncertainty\n",
    "    count_period = text.count(\".\")         # Sentence boundaries\n",
    "    count_comma = text.count(\",\")          # Clause complexity\n",
    "    \n",
    "    # Total non-alphanumeric, non-space characters\n",
    "    count_punct_total = sum(1 for ch in text if (not ch.isalnum()) and (not ch.isspace()))\n",
    "    \n",
    "    # Stylistic features: Capture writing style indicators\n",
    "    count_upper_tokens = sum(1 for t in word_tokens if is_all_caps_token(t))\n",
    "    ratio_upper_tokens = (count_upper_tokens / T) if T > 0 else 0.0\n",
    "    \n",
    "    # Elongated words indicate emphasis, any character repeated 3+ times\n",
    "    count_elongated = sum(1 for t in toks_lower \n",
    "                         if any(ch.isalpha() for ch in t) and re.search(r\"(.)\\1{2,}\", t))\n",
    "    \n",
    "    # Sentiment modifier features\n",
    "    count_negations = sum(1 for t in toks_lower if t in NEGATIONS) + text.lower().count(\"n't\")\n",
    "    \n",
    "    # Intensifiers amplify sentiment strength\n",
    "    count_intensifiers = sum(1 for t in toks_lower if t in INTENSIFIERS)\n",
    "    \n",
    "    # Emoticon features: Direct sentiment indicators\n",
    "    tl = text.lower()\n",
    "    count_pos_emotes = sum(tl.count(e.strip()) for e in POS_EMOTES)\n",
    "    count_neg_emotes = sum(tl.count(e.strip()) for e in NEG_EMOTES)\n",
    "    \n",
    "    # Length features: Basic text statistics\n",
    "    len_tokens = float(T)\n",
    "    len_chars = float(L)\n",
    "    avg_tok_len = (len_chars / len_tokens) if T > 0 else 0.0\n",
    "    \n",
    "    # features to comparable ranges\n",
    "    T_norm = max(T, 1.0)\n",
    "    \n",
    "    # Normalize each feature to prevent any single feature from dominating\n",
    "    feats = {\n",
    "        \n",
    "        # Length features: scale relative to text size\n",
    "        \"len_tokens_norm\": len_tokens / max(T_norm, 20.0),\n",
    "        \"len_chars_norm\": len_chars / (4.0 * T_norm),  # Assume ~4 chars per token\n",
    "        \"avg_tok_len_norm\": avg_tok_len / 10.0,\n",
    "        \n",
    "        # Punctuation: normalize by token count\n",
    "        \"count_exclaim_norm\": count_exclaim / T_norm,\n",
    "        \"count_question_norm\": count_question / T_norm,\n",
    "        \"count_period_norm\": count_period / T_norm,\n",
    "        \"count_comma_norm\": count_comma / T_norm,\n",
    "        \"count_punct_total_norm\": count_punct_total / max(L, 1.0),\n",
    "        \n",
    "        # Uppercase: scale by half token count (typically rare)\n",
    "        \"count_upper_tokens_norm\": count_upper_tokens / max(T_norm/2.0, 1.0),\n",
    "        \"ratio_upper_tokens_norm\": ratio_upper_tokens,  # Already a ratio\n",
    "        \n",
    "        # Style modifiers: normalize by token count\n",
    "        \"count_elongated_norm\": count_elongated / T_norm,\n",
    "        \"count_negations_norm\": count_negations / T_norm,\n",
    "        \"count_intensifiers_norm\": count_intensifiers / T_norm,\n",
    "        \n",
    "        # Emoticons: raw counts (typically 0-2)\n",
    "        \"count_pos_emotes_norm\": float(count_pos_emotes),\n",
    "        \"count_neg_emotes_norm\": float(count_neg_emotes),\n",
    "    }\n",
    "    return feats\n",
    "\n",
    "\n",
    "print(\"Building feature validation dataset...\")\n",
    "feat_rows = []\n",
    "\n",
    "# Extract features for each training example\n",
    "for idx, row in train_df.iterrows():\n",
    "    feats = compute_features_for_text(row['sentence'])\n",
    "    feats[\"label\"] = row['label']  # Attach ground truth label\n",
    "    feat_rows.append(feats)\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "df_features = pd.DataFrame(feat_rows)\n",
    "\n",
    "# Get list of normalized feature columns (exclude label)\n",
    "feature_cols = [c for c in df_features.columns if c.endswith(\"_norm\")]\n",
    "\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Training samples: {len(df_features)}\")\n",
    "\n",
    "\n",
    "# Prepare feature matrix and labels\n",
    "X_chi = df_features[feature_cols].values\n",
    "y_chi = df_features[\"label\"].values\n",
    "\n",
    "# Chi-square test measures dependency between each feature and the label\n",
    "# Higher chi2 score = stronger association with sentiment\n",
    "chi_vals, p_vals = chi2(X_chi, y_chi)\n",
    "\n",
    "# Create ranking table\n",
    "chi_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"chi2_score\": chi_vals,      # Higher = more informative\n",
    "    \"p_value\": p_vals            # Lower = more statistically significant\n",
    "}).sort_values(\"chi2_score\", ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking (Chi-square):\")\n",
    "print(chi_df.to_string(index=False))\n",
    "\n",
    "# Extract features from validation set\n",
    "val_feat_rows = []\n",
    "for idx, row in val_df.iterrows():\n",
    "    feats = compute_features_for_text(row['sentence'])\n",
    "    feats[\"label\"] = row['label']\n",
    "    val_feat_rows.append(feats)\n",
    "\n",
    "df_val = pd.DataFrame(val_feat_rows)\n",
    "\n",
    "# Prepare train/val splits\n",
    "X_train_lr = df_features[feature_cols].values\n",
    "y_train_lr = df_features[\"label\"].values\n",
    "X_val_lr = df_val[feature_cols].values\n",
    "y_val_lr = df_val[\"label\"].values\n",
    "\n",
    "# Standardize features (zero mean, unit variance)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_lr)\n",
    "X_val_scaled = scaler.transform(X_val_lr)\n",
    "\n",
    "# Train logistic regression classifier\n",
    "lr_model = LogisticRegression(max_iter=1000, solver=\"liblinear\")\n",
    "lr_model.fit(X_train_scaled, y_train_lr)\n",
    "\n",
    "# Evaluate on validation set\n",
    "lr_pred = lr_model.predict(X_val_scaled)\n",
    "lr_acc = accuracy_score(y_val_lr, lr_pred)\n",
    "\n",
    "print(f\"\\nLR Baseline validation accuracy: {lr_acc:.4f}\")\n",
    "print(f\"Conclusion: Hand-crafted features alone achieve {lr_acc*100:.1f}% classification ability\")\n",
    "\n",
    "# Select features with chi-square score above threshold\n",
    "IMPORTANCE_THRESHOLD = 1.0\n",
    "selected_features = chi_df[chi_df[\"chi2_score\"] > IMPORTANCE_THRESHOLD][\"feature\"].tolist()\n",
    "\n",
    "print(f\"Based on chi-square > {IMPORTANCE_THRESHOLD}, selected {len(selected_features)} features:\")\n",
    "for feat in selected_features:\n",
    "    chi_val = chi_df[chi_df[\"feature\"] == feat][\"chi2_score\"].values[0]\n",
    "    print(f\"   - {feat:<30} (chi2={chi_val:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d4f34",
   "metadata": {},
   "source": [
    "## DataLoader Setup\n",
    "\n",
    "Create efficient data pipelines that feed batches of samples to the model during training.\n",
    "\n",
    "### Dataset Class\n",
    "\n",
    "Wrap preprocessed data in PyTorch's Dataset interface. PyTorch's DataLoader requires this structure for efficient batching and data loading\n",
    "\n",
    "This pipeline ensures our text data is properly prepared for the LSTM model while maintaining reproducibility and preventing data leakage.\n",
    "\n",
    "\n",
    "### Compute Numeric Feature Function\n",
    "\n",
    "The function processes batches of tokenized text in real-time, converting token IDs back to their string representations to analyze character-level patterns (punctuation, capitalization, emoticons) that aren't captured by word embeddings alone. These features are then normalized to comparable scales and concatenated with the neural network's learned representations, creating a richer input that combines learned semantic knowledge with explicit linguistic rules.\n",
    "\n",
    "In the neural network forward pass, this function is called to compute features for each batch.\n",
    "\n",
    "### Collate Function \n",
    "\n",
    "Sentences have variable lengths (e.g., 5 words vs 20 words), but neural networks require fixed-size tensors. To address this, pad shorter sequences with special `<pad>` tokens to match the longest sequence in each batch\n",
    "\n",
    "### Training DataLoader\n",
    "- `shuffle=True`: Randomize sample order each epoch to prevent overfitting to data order, which is critical for good generalization\n",
    "\n",
    "- `batch_size=128`: Balance between speed and memory, 128 is a common choice for medium datasets\n",
    "\n",
    "### Validation/Test DataLoaders\n",
    "- `shuffle=False`: Keep fixed order to reproducible evaluation metrics\n",
    "\n",
    "- `pin_memory=True`: Speed up CPU→GPU transfer. Only beneficial when using MPS\n",
    "\n",
    "This setup ensures our data flows efficiently from disk → CPU → GPU during training while maintaining reproducibility for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c62c293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes - Train: 6568, Val: 825, Test: 1749\n",
      "\n",
      "Batch info:\n",
      "Type: <class 'types.SimpleNamespace'>\n",
      "Text shape: torch.Size([128, 51])\n",
      "Label shape: torch.Size([128])\n",
      "Sample text (first 10 tokens): tensor([  56,  166, 1611,    7,   81,  583,    6,  925,  605,    2])\n",
      "Sample label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaowenrou/Documents/Lincoln/COMP647-1159501/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Define Custom PyTorch Dataset Class for accessing individual samples during training\n",
    "class SST2Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for SST-2 sentiment classification.\n",
    "    Converts text sentences into numerical representations (token IDs) and pairs them with their corresponding labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, stoi):\n",
    "        \"\"\"\n",
    "        Initialize the dataset by preprocessing all samples.\n",
    "        \"\"\"\n",
    "        # Pre-process all data and store in memory\n",
    "        self.data = []\n",
    "        # Iterate through each row in the dataframe\n",
    "        for _, row in dataframe.iterrows():\n",
    "            sentence = row['sentence']\n",
    "            label = int(row['label'])\n",
    "            # Convert sentence to list of integer IDs\n",
    "            ids = [stoi.get(w, stoi[UNK]) for w in tokenize(sentence)]\n",
    "            # Store as dictionary for easy access\n",
    "            self.data.append({'input_ids': ids, 'label': label})\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Return a single sample at the given index.\n",
    "        This is called by DataLoader to fetch individual samples.\n",
    "        \"\"\"\n",
    "        return self.data[idx]\n",
    "\n",
    "# Instantiate dataset objects for each split\n",
    "# These objects will be used by DataLoader during training\n",
    "train_ds = SST2Dataset(train_df, stoi)\n",
    "val_ds = SST2Dataset(val_df, stoi)\n",
    "test_ds = SST2Dataset(test_df, stoi)\n",
    "# Display dataset sizes for verification\n",
    "print(f\"Dataset sizes - Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")\n",
    "\n",
    "\n",
    "# Extract hand-crafted linguistic features from tokenized text batches.\n",
    "def compute_numeric_features(x_ids, pad_idx, selected_feat_names):\n",
    "    \"\"\"\n",
    "    This function converts token IDs back to text and computes numerical features\n",
    "    that capture sentiment-related linguistic patterns. These features complement\n",
    "    neural network representations by explicitly encoding domain knowledge about\n",
    "    sentiment expression.\n",
    "    \"\"\"\n",
    "    # Preserve the device (CPU/GPU) of input tensor to ensure output stays on same device\n",
    "    device = x_ids.device\n",
    "    \n",
    "    # Get batch size (B) and sequence length (T)\n",
    "    B, T = x_ids.size()\n",
    "    \n",
    "    # List to accumulate feature vectors for each sample in the batch\n",
    "    feats_list = []\n",
    "    \n",
    "    # Process each text sample in the batch independently\n",
    "    for i in range(B):\n",
    "        # Extract token IDs for current sample and convert to Python list\n",
    "        ids = x_ids[i].tolist()\n",
    "        \n",
    "        # Remove padding tokens - only analyze actual content\n",
    "        ids = [t for t in ids if t != pad_idx]\n",
    "        \n",
    "        # Map token IDs back to string tokens using vocabulary\n",
    "        toks = [TEXT.vocab.itos[t] for t in ids]\n",
    "        \n",
    "        # Reconstruct the original text by joining tokens with spaces\n",
    "        text = \" \".join(toks)\n",
    "        \n",
    "        # Compute basic text statistics\n",
    "        len_tokens = float(len(toks))          # Number of word tokens\n",
    "        len_chars = float(len(text))           # Total character count\n",
    "        avg_tok_len = (len_chars / len_tokens) if len_tokens > 0 else 0.0  # Average word length\n",
    "        \n",
    "        # Count punctuation marks (emotional expression indicators)\n",
    "        count_exclaim = float(text.count(\"!\"))\n",
    "        count_question = float(text.count(\"?\"))\n",
    "        count_period = float(text.count(\".\"))\n",
    "        count_comma = float(text.count(\",\"))\n",
    "        \n",
    "        # Count all non-alphanumeric, non-space characters (overall punctuation density)\n",
    "        count_punct_total = float(sum(1 for ch in text if (not ch.isalnum()) and (not ch.isspace())))\n",
    "        \n",
    "        # Analyze capitalization patterns (emphasis/shouting)\n",
    "        count_upper_tokens = float(sum(1 for tok in toks if is_all_caps_token(tok)))\n",
    "        \n",
    "        # Ratio of uppercase tokens to total tokens\n",
    "        ratio_upper_tokens = (count_upper_tokens / len_tokens) if len_tokens > 0 else 0.0\n",
    "        \n",
    "        # Detect elongated words (informal emphasis)\n",
    "        count_elongated = float(sum(1 for tok in toks if re.search(r\"(.)\\1{2,}\", tok or \"\")))\n",
    "        \n",
    "        # Count sentiment modifiers\n",
    "        toks_lower = [t.lower() for t in toks]\n",
    "        \n",
    "        # Count negation words (sentiment polarity reversers)\n",
    "        count_negations = float(sum(1 for t in toks_lower if t in NEGATIONS))\n",
    "        \n",
    "        # Count intensifier words (sentiment amplifiers)\n",
    "        count_intensifiers = float(sum(1 for t in toks_lower if t in INTENSIFIERS))\n",
    "        \n",
    "        # Count emoticons (direct sentiment signals)\n",
    "        tl = text.lower()  # Lowercase for case-insensitive emoticon matching\n",
    "        \n",
    "        # Sum occurrences of positive emoticons\n",
    "        count_pos_emotes = float(sum(tl.count(e.strip()) for e in POS_EMOTES))\n",
    "        \n",
    "        # Sum occurrences of negative emoticons\n",
    "        count_neg_emotes = float(sum(tl.count(e.strip()) for e in NEG_EMOTES))\n",
    "        \n",
    "        # Store raw feature values\n",
    "        all_feats = {\n",
    "            \"len_tokens\": len_tokens,\n",
    "            \"len_chars\": len_chars,\n",
    "            \"avg_tok_len\": avg_tok_len,\n",
    "            \"count_exclaim\": count_exclaim,\n",
    "            \"count_question\": count_question,\n",
    "            \"count_period\": count_period,\n",
    "            \"count_comma\": count_comma,\n",
    "            \"count_punct_total\": count_punct_total,\n",
    "            \"count_upper_tokens\": count_upper_tokens,\n",
    "            \"ratio_upper_tokens\": ratio_upper_tokens,\n",
    "            \"count_elongated\": count_elongated,\n",
    "            \"count_negations\": count_negations,\n",
    "            \"count_intensifiers\": count_intensifiers,\n",
    "            \"count_pos_emotes\": count_pos_emotes,\n",
    "            \"count_neg_emotes\": count_neg_emotes,\n",
    "        }\n",
    "        \n",
    "        # Use actual token count for normalization, with minimum of 1.0 to avoid division by zero\n",
    "        T_norm = max(T, 1.0)\n",
    "        \n",
    "        all_feats_norm = {\n",
    "            # Length features: normalize by typical text size\n",
    "            \"len_tokens_norm\": all_feats[\"len_tokens\"] / max(T_norm, 20.0),\n",
    "            \"len_chars_norm\": all_feats[\"len_chars\"] / (4.0 * T_norm),\n",
    "            \"avg_tok_len_norm\": all_feats[\"avg_tok_len\"] / 10.0,\n",
    "            \n",
    "            # Punctuation features: normalize by token count\n",
    "            \"count_exclaim_norm\": all_feats[\"count_exclaim\"] / T_norm,\n",
    "            \"count_question_norm\": all_feats[\"count_question\"] / T_norm,\n",
    "            \"count_period_norm\": all_feats[\"count_period\"] / T_norm,\n",
    "            \"count_comma_norm\": all_feats[\"count_comma\"] / T_norm,\n",
    "            \"count_punct_total_norm\": all_feats[\"count_punct_total\"] / max(len(text), 1.0),\n",
    "            \n",
    "            # Uppercase features: scale by half token count\n",
    "            \"count_upper_tokens_norm\": all_feats[\"count_upper_tokens\"] / max(T_norm/2.0, 1.0),\n",
    "            \"ratio_upper_tokens_norm\": all_feats[\"ratio_upper_tokens\"],\n",
    "            \n",
    "            # Style modifier features: normalize by token count\n",
    "            \"count_elongated_norm\": all_feats[\"count_elongated\"] / T_norm,\n",
    "            \"count_negations_norm\": all_feats[\"count_negations\"] / T_norm,\n",
    "            \"count_intensifiers_norm\": all_feats[\"count_intensifiers\"] / T_norm,\n",
    "            \n",
    "            # Emoticon features: use raw counts\n",
    "            \"count_pos_emotes_norm\": all_feats[\"count_pos_emotes\"],\n",
    "            \"count_neg_emotes_norm\": all_feats[\"count_neg_emotes\"],\n",
    "        }\n",
    "        \n",
    "        # Extract only the selected features\n",
    "        selected_vals = [all_feats_norm[fname] for fname in selected_feat_names]\n",
    "        \n",
    "        # Add this sample's feature vector to the batch list\n",
    "        feats_list.append(selected_vals)\n",
    "    \n",
    "    # Convert to tensor and return\n",
    "    return torch.tensor(feats_list, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "# Neural networks require fixed-size inputs for efficient batch processing\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to process a batch of samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize lists to collect input sequences and labels\n",
    "    ids_list = []\n",
    "    labels = []\n",
    "    \n",
    "    # Extract data from each sample in the batch\n",
    "    for item in batch:\n",
    "        ids = item['input_ids']\n",
    "        label = item['label']\n",
    "        ids_list.append(ids)\n",
    "        labels.append(label)\n",
    "    \n",
    "    # Find the maximum sequence length in this batch\n",
    "    max_len = max(len(x) for x in ids_list)\n",
    "    \n",
    "    # Create a tensor filled with padding_idx (0)\n",
    "    # All positions are initialized to padding_idx and will be overwritten with actual tokens\n",
    "    x = torch.full((len(ids_list), max_len), padding_idx, dtype=torch.long)\n",
    "    \n",
    "    # Fill in the actual token IDs for each sequence\n",
    "    for i, ids in enumerate(ids_list):\n",
    "        # Copy token IDs to the beginning of each row\n",
    "        x[i, :len(ids)] = torch.tensor(ids, dtype=torch.long)\n",
    "    \n",
    "    # Convert labels list to tensor\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    # Return as SimpleNamespace for convenient attribute access\n",
    "    return types.SimpleNamespace(text=x, label=y)\n",
    "\n",
    "# Create DataLoader Objects\n",
    "# PyTorch utility that handles batching, shuffling, and parallel data loading\n",
    "\n",
    "# Training DataLoader\n",
    "train_iter = DataLoader(\n",
    "    train_ds,              # Dataset object to load from\n",
    "    batch_size=128,        # Number of samples per batch\n",
    "    shuffle=True,          # Randomly shuffle data each epoch\n",
    "    collate_fn=collate_fn, # Our custom function to combine samples into batches\n",
    "    pin_memory=True        # If True, allocates tensors in pinned memory\n",
    ")\n",
    "\n",
    "# Validation DataLoader\n",
    "val_iter = DataLoader(\n",
    "    val_ds,                # Validation dataset\n",
    "    batch_size=128,        # Same batch size as training for consistency\n",
    "    shuffle=False,         # DON'T shuffle validation data\n",
    "    collate_fn=collate_fn, # Same collate function\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Test DataLoader\n",
    "test_iter = DataLoader(\n",
    "    test_ds,               # Test dataset\n",
    "    batch_size=128,\n",
    "    shuffle=False,         # DON'T shuffle test data\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "# Get the first batch from training DataLoader\n",
    "first = next(iter(train_iter))\n",
    "\n",
    "# Display batch information for verification\n",
    "print(f\"\\nBatch info:\")\n",
    "print(f\"Type: {type(first)}\")  \n",
    "print(f\"Text shape: {first.text.shape}\")  \n",
    "print(f\"Label shape: {first.label.shape}\")  \n",
    "print(f\"Sample text (first 10 tokens): {first.text[0][:10]}\")  \n",
    "print(f\"Sample label: {first.label[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b794b5e",
   "metadata": {},
   "source": [
    "## BiLSTM Sentiment Classification Model\n",
    "\n",
    "For sentiment classification, we employ a Bidirectional Long Short-Term Memory (BiLSTM) network as our primary algorithm. This choice is justified by several key advantages:\n",
    "\n",
    "1. Sequential Nature of Language: Text is not just a collection of random words—the order matters tremendously. LSTMs are designed specifically to process sequences where order matters. As the LSTM reads through a sentence word by word, it maintains a \"memory\" of what it has seen before. \n",
    "\n",
    "2. Long-Range Dependency Modeling: Sometimes the key to understanding sentiment is remembering something from much earlier in the text. RNNs  try to do this but fail because they forget information from earlier in the sequence. LSTMs solve this problem using special mechanisms called \"gates\" that act like memory controllers. \n",
    "\n",
    "3. Bidirectional Context Capture: A regular LSTM only reads left-to-right (forward). A Bidirectional LSTM  reading the sentence in both directions simultaneously: one LSTM reads left-to-right (forward), and another reads right-to-left (backward). By combining information from both directions, the model gets the complete picture, leading to much better understanding of sentiment.\n",
    "\n",
    "4. Hierarchical Representation Learning: We use 2 LSTM layers stacked on top of each other, which allows the model to learn patterns at different levels of abstraction. Our first LSTM layer learns basic patterns like grammar and simple word combinations. The second LSTM layer then takes these basic patterns and learns more complex, abstract patterns. \n",
    "\n",
    "### Metrics\n",
    "\n",
    "#### 1. Classification Accuracy\n",
    "\n",
    "We mainly use classification accuracy as our primary performance measure. \n",
    "\n",
    "Classification accuracy is the most appropriate metric for our sentiment analysis task. First, our dataset exhibits balanced class distribution—we have roughly equal numbers of positive and negative reviews, meaning accuracy won't be misleadingly inflated by predicting the majority class.\n",
    "\n",
    "Second, for binary sentiment classification, both classes (positive/negative) are equally important. We don't have an asymmetric cost structure where false positives are more costly than false negatives, so accuracy's equal weighting of all errors is appropriate.\n",
    "\n",
    "#### 2. Cross-Entropy Loss\n",
    "\n",
    "We also monitor cross-entropy loss during training and validation.\n",
    "\n",
    "Cross-entropy loss measures the divergence between predicted probability distributions and true labels, providing a more nuanced signal than accuracy during training. Cross-entropy rewards confident correct predictions and penalizes confident wrong predictions more heavily. \n",
    "\n",
    "Cross-entropy is the natural choice for neural network classification because it's the negative log-likelihood of the correct class, making it theoretically grounded in maximum likelihood estimation. It's also convex with respect to the final layer's logits, ensuring stable gradient descent optimization. \n",
    "\n",
    "### Overfitting and Underfitting Prevention\n",
    "\n",
    "#### 1. Overfitting Prevention\n",
    "\n",
    "1. Frozen Pretrained Embeddings: GloVe embeddings are pretrained on billions of words from Wikipedia and news corpora. These vectors already encode rich semantic relationships. By freezing these weights, we prevent the model from overfitting embeddings to our small training set (6,568 samples). \n",
    "\n",
    "\n",
    "2. Dropout Regularization: Dropout randomly sets activations to zero during training with probability `p`, forcing the network to learn redundant representations. If the model relies on a single neuron to detect \"not,\" and that neuron is dropped out 50% of the time, the model must learn alternative pathways to detect negation.\n",
    "\n",
    "3. Early Stopping with Model Checkpointing: Training for too many epochs inevitably leads to overfitting—the model continues improving on training data while validation performance degrades. Early stopping prevents this by monitoring validation loss and saving the model checkpoint when it achieves the lowest validation loss. After 50 epochs, even if the final model is overfit, we retain the best-performing model from earlier in training (typically around epochs 15-25).\n",
    "\n",
    "4. Train-Validation Monitoring: Explicit monitoring of the train-validation gap provides a human-interpretable diagnostic for model health. A gap of 2-5% is normal and acceptable—it indicates the model has learned patterns specific to training data but still generalizes well. A gap exceeding 10% signals severe overfitting, prompting us to stop training, increase regularization, or reduce model capacity.\n",
    "\n",
    "### 2. Underfitting Prevention\n",
    "\n",
    "1. Sufficient Model Capacity: 2-layer BiLSTM with 384 hidden units provides `384 × 2 directions × 2 layers = 1,536` hidden states across the network, sufficient to learn nuanced linguistic patterns.\n",
    "\n",
    "2. Adequate Training Duration: Training for 50 epochs with early stopping ensures we explore enough of the loss landscape. If validation loss is still decreasing at epoch 50, we'd extend training, but typically loss plateaus around epoch 20-30.\n",
    "\n",
    "3. High Initial Learning Rate: Starting with LR=0.15 ensures rapid initial learning. Too small a learning rate (e.g., 0.001) would cause extremely slow convergence, potentially getting stuck in poor local minima and resulting in underfitting.\n",
    "\n",
    "4. Monitoring Training Loss: If training loss remains high (>0.5) throughout training, this signals underfitting—the model lacks capacity or training time to fit the data. We'd respond by adding layers, or training longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7edd5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration:\n",
      "Vocabulary size: 6864\n",
      "Embedding dimension: 100\n",
      "Hidden dimension: 256\n",
      "Number of features: 9\n",
      "\n",
      "Starting training...\n",
      "Epoch 10: Train Loss=0.657, Val Loss=0.641\n",
      "  Train Acc=0.627, Val Acc=0.650\n",
      "Epoch 20: Train Loss=0.613, Val Loss=0.574\n",
      "  Train Acc=0.712, Val Acc=0.724\n",
      "Epoch 30: Train Loss=0.579, Val Loss=0.544\n",
      "  Train Acc=0.695, Val Acc=0.710\n",
      "Epoch 40: Train Loss=0.568, Val Loss=0.561\n",
      "  Train Acc=0.737, Val Acc=0.745\n",
      "Epoch 50: Train Loss=0.541, Val Loss=0.642\n",
      "  Train Acc=0.684, Val Acc=0.661\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 256  # hidden dimension for LSTM\n",
    "label_size = 2  # binary classification\n",
    "num_features = len(selected_features)  # number of hand-crafted features\n",
    "\n",
    "# Print model configuration\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Embedding dimension: {embedding_dim}\")\n",
    "print(f\"Hidden dimension: {hidden_dim}\")\n",
    "print(f\"Number of features: {num_features}\")\n",
    "\n",
    "\n",
    "# Define BiLSTM classifier\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size, padding_idx, num_features, feat_names):\n",
    "        super(BiLSTMClassifier, self).__init__()  # initialize parent class\n",
    "        \n",
    "        # Create embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        # Load pretrained word vectors\n",
    "        self.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "        # Freeze embedding weights\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        # Create bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Feature projection layer\n",
    "        self.feat_layer = nn.Linear(num_features, 32)\n",
    "        # Final classification layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2 + 32, output_size)\n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Store padding index\n",
    "        self.pad_idx = padding_idx\n",
    "        # Store feature names\n",
    "        self.feat_names = feat_names\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get word embeddings\n",
    "        embedded = self.embedding(x)\n",
    "        # Apply dropout\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # Pass through LSTM\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        # Concatenate forward and backward hidden states\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        \n",
    "        # Extract hand-crafted features\n",
    "        features = compute_numeric_features(x, self.pad_idx, self.feat_names)\n",
    "        # Project features\n",
    "        features = self.feat_layer(features)\n",
    "        \n",
    "        # Combine LSTM output and features\n",
    "        combined = torch.cat([hidden, features], dim=1)\n",
    "        # Get final prediction\n",
    "        out = self.fc(combined)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = BiLSTMClassifier(vocab_size, embedding_dim, hidden_dim, label_size, padding_idx, num_features, selected_features)\n",
    "# Move model to device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Set initial learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Training function\n",
    "def train_model(model, data_loader, criterion, lr):\n",
    "    model.train()  # set model to training mode\n",
    "    total_loss = 0  # initialize total loss\n",
    "    \n",
    "    # Loop through batches\n",
    "    for batch in data_loader:\n",
    "        # Get input and labels\n",
    "        x = batch.text.to(device)\n",
    "        y = batch.label.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(x)\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Manual parameter update\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():  # loop through all parameters\n",
    "                if param.grad is not None:  # check if gradient exists\n",
    "                    param.data = param.data - lr * param.grad  # update weights\n",
    "                    param.grad.zero_()  # reset gradients\n",
    "        \n",
    "        # Accumulate loss\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Return average loss\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def eval_model(model, data_loader, criterion):\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    total_loss = 0  # initialize total loss\n",
    "    \n",
    "    # No gradient computation needed\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:  # loop through batches\n",
    "            # Get input and labels\n",
    "            x = batch.text.to(device)\n",
    "            y = batch.label.to(device)\n",
    "            # Forward pass\n",
    "            output = model(x)\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, y)\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    # Return average loss\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def get_accuracy(model, data_loader):\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    correct = 0  # count of correct predictions\n",
    "    total = 0  # total number of samples\n",
    "    \n",
    "    # No gradient computation needed\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:  # loop through batches\n",
    "            # Get input and labels\n",
    "            x = batch.text.to(device)\n",
    "            y = batch.label.to(device)\n",
    "            # Forward pass\n",
    "            output = model(x)\n",
    "            # Get predicted class\n",
    "            _, pred = torch.max(output, 1)\n",
    "            # Update total count\n",
    "            total += y.size(0)\n",
    "            # Update correct count\n",
    "            correct += (pred == y).sum().item()\n",
    "    \n",
    "    # Return accuracy\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# Set number of epochs\n",
    "epochs = 50\n",
    "# Initialize best loss\n",
    "best_loss = 999999\n",
    "\n",
    "# Lists to store metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "# Start training\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Train for one epoch\n",
    "    train_loss = train_model(model, train_iter, criterion, learning_rate)\n",
    "    # Evaluate on validation set\n",
    "    val_loss = eval_model(model, val_iter, criterion)\n",
    "    \n",
    "    # Calculate accuracies\n",
    "    train_acc = get_accuracy(model, train_iter)\n",
    "    val_acc = get_accuracy(model, val_iter)\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss  # update best loss\n",
    "        best_model = copy.deepcopy(model)  # save model copy\n",
    "    \n",
    "    # Reduce learning rate every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        learning_rate = learning_rate * 0.8  # multiply by 0.8\n",
    "    \n",
    "    # Print progress every 5 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1}: Train Loss={train_loss:.3f}, Val Loss={val_loss:.3f}')\n",
    "        print(f'  Train Acc={train_acc:.3f}, Val Acc={val_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb48e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a699d800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance Comparison:\n",
      "  Logistic Regression Baseline:  0.5952\n",
      "  BiLSTM + Feature Fusion (val): 0.7697\n",
      "  BiLSTM + Feature Fusion (test):0.7679\n",
      "Summary:\n",
      "  1. Feature Validation: LR baseline 0.5952\n",
      "  2. Deep Model: BiLSTM with feature fusion achieved 0.7679\n"
     ]
    }
   ],
   "source": [
    "test_acc = get_accuracy(best_model, test_iter)\n",
    "\n",
    "print(\"\\nPerformance Comparison:\")\n",
    "print(f\"  Logistic Regression Baseline:  {lr_acc:.4f}\")\n",
    "print(f\"  BiLSTM + Feature Fusion (val): {max(val_accs):.4f}\")\n",
    "print(f\"  BiLSTM + Feature Fusion (test):{test_acc:.4f}\")\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(f\"  1. Feature Validation: LR baseline {lr_acc:.4f}\")\n",
    "print(f\"  2. Deep Model: BiLSTM with feature fusion achieved {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
